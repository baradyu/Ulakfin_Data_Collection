def hsbc_func():
    print('HSBC Yatırım')
    from fuzzywuzzy import process
    import requests as req
    from datetime import date
    import pandas as pd
    from selenium import webdriver
    import time
    from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
    from pdfminer.pdfpage import PDFPage
    from pdfminer.converter import TextConverter
    from pdfminer.layout import LAParams
    import io
    import re
    import datetime
    from slack import WebClient
    from selenium.common.exceptions import NoSuchElementException
    import requests
    import json
    print('Modules imported')

    #GETTING PDF AS TEXT
    def download_pdf(url):
        local_filename = url.split('/')[-1]

        with req.get(url) as r:
            with open(local_filename, 'wb') as f:
                f.write(r.content)

        return  local_filename

    slack_token = 'xoxb-1310569939731-1373479534900-EAQbiKWSTqT0TxoJI7EfM5TP'
    slack_channel = '#csv'
    slack_icon_url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTuGqps7ZafuzUsViFGIremEL2a3NR0KO0s0RTCMXmzmREJd5m4MA&s'
    slack_user_name = 'informer'
    def post_message_to_slack(text, blocks=None):
        return requests.post('https://slack.com/api/chat.postMessage', {
            'token': slack_token,
            'channel': slack_channel,
            'text': text,
            'icon_url': slack_icon_url,
            'username': slack_user_name,
            'blocks': json.dumps(blocks) if blocks else None
        }).json()

    # Şirket adı, hisse ismi eşleştirme
    def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=2):
        s = df_2[key2].tolist()
        m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))
        df_1['matches'] = m
        m2 = df_1['matches'].apply(lambda x: ', '.join([j[0] for j in x if j[1] >= threshold]))
        df_1['matches'] = m2
        return df_1

    # Listeyi tek boyutlu yapma
    def flatten(l):
        try:
            return flatten(l[0]) + (flatten(l[1:]) if len(l) > 1 else []) if type(l) is list else [l]
        except IndexError:
            return []
    def pdf_to_text(path):
        manager = PDFResourceManager()
        retstr = io.StringIO()
        layout = LAParams(all_texts=True)
        device = TextConverter(manager, retstr, laparams=layout)
        filepath = open(path, 'rb')
        interpreter = PDFPageInterpreter(manager, device)
        for page in PDFPage.get_pages(filepath, check_extractable=False):
            interpreter.process_page(page)
        text = retstr.getvalue()
        filepath.close()
        device.close()
        retstr.close()
        return text

    ay = date.today().strftime("%B")
    today = date.today().strftime('%d.%m.%Y')

    months_xpath = {
        "January": "//span/span/span[2]/ul/li[1]",
        "February": "//span/span/span[2]/ul/li[2]",
        "March": "//span/span/span[2]/ul/li[3]",
        "April": "//span/span/span[2]/ul/li[4]",
        "May": "//span/span/span[2]/ul/li[5]",
        "June": "//span/span/span[2]/ul/li[6]",
        "July": "//span/span/span[2]/ul/li[7]",
        "August": "//span/span/span[2]/ul/li[8]",
        "September": "//span/span/span[2]/ul/li[9]",
        "October": "//span/span/span[2]/ul/li[10]",
        "November": "//span/span/span[2]/ul/li[11]",
        "December": "//span/span/span[2]/ul/li[12]"
    }

    option = webdriver.ChromeOptions()
    option.add_argument("--incognito")
    driver = webdriver.Chrome(executable_path='C:/Users/berat/webdriver/chromedriver', options=option)        ###
    print('Webdriver is set.')
    print('Getting to the daily news page.')
    driver.get("http://www.hsbcyatirim.com.tr/hizmetlerimiz/arastirma/arastirma")
    link_url = 'http://www.hsbcyatirim.com.tr/hizmetlerimiz/arastirma/arastirma'
    print(f'Current webpage : {link_url}')
    time.sleep(2)
    driver.find_element_by_xpath("//*[@id='select2-ddlMonth-container']").click()
    month_xpath = months_xpath.get(f"{ay}")
    driver.find_element_by_xpath(month_xpath).click()
    time.sleep(2)
    driver.find_element_by_xpath("//*[@id='GetFundProfit']").click()
    time.sleep(3)
    try:
        for c in range(1,25):
            tarih_xpath = f'//*[@id="ContentSection"]/div[2]/div/div[3]/div[2]/table/tbody/tr[{c}]/td[2]'
            element = driver.find_element_by_xpath(tarih_xpath)
            if element.text == today:
                driver.find_element_by_xpath(
                    f'//*[@id="ContentSection"]/div[2]/div/div[3]/div[2]/table/tbody/tr[{c}]/td[1]/a').click()
                break

        driver.switch_to.window(driver.window_handles[-1])
        hsbc_url = driver.current_url
        link_url = hsbc_url
        print(f'Current webpage : {link_url}')
        print('Downloading PDF')
        hsbc = download_pdf(hsbc_url)
        print('PDF is downloaded')

        pdf_file = f"C:/Users/berat/Desktop/Ulakfin - Ortak Data/slack_csv_folded/HSBC_Yatırım/{hsbc}"
        print('Setting the boundaries between Doküman  HSBC  Yatırım  Menkul  Değerler and Şirket Haberleri')
        sirket_haberleri_pattern = '(?<=Şirket Haberleri).*?(?=Doküman  HSBC  Yatırım  Menkul  Değerler)'
        text_list = []
        sirket_haber_list_1 =[]
        text_list.append(pdf_to_text(pdf_file))
        if text_list[0].find('Şirket Haberleri')!=-1:
            for text in text_list:
                sirket_haber_list_1.append(re.findall(sirket_haberleri_pattern, text, re.DOTALL))

            for element in sirket_haber_list_1:
                for element2 in element:
                    text = element2

            lines = text.splitlines()
            haberler=[]
            hisseler=[]
            tarih=[]
            bulten=[]

            print('Cleaning the data')
            for line in lines:
                if line.isupper():
                    hisseler.append(line)
                    today = datetime.datetime.now().date()
                    tarih.append(today)
                    bulten.append('HSBC')
                elif line!=' ' and line!='' and len(hisseler)==len(haberler):
                    haberler[-1] = haberler[-1] + line
                elif line!=' ' and line!='' and len(hisseler)>len(haberler):
                    haberler.append(line)

            timestamp = []
            news_id = []
            for q in hisseler:
                timestamp.append(datetime.datetime.today().now().time())
                c = 0
                news_id.append(c)
                c = c + 1

            news1 = []
            for i in range(0, len(haberler)):
                news_pr = haberler[i].split('\n')
                news_pr_strip = []
                for k in range(0, len(news_pr)):
                    news_pr_strip.append(news_pr[k].strip())
                news1.append(" ".join(news_pr_strip))
            haberler = news1

            link = []
            for h in hisseler:
                link.append(link_url)
            link = flatten(link)

            hisseler_df = pd.DataFrame(columns=['codes'], data=hisseler)
            haberler_df = pd.DataFrame(columns=['news'], data=haberler)
            tarih_df = pd.DataFrame(columns=['date_list'], data=tarih)
            bulten_df = pd.DataFrame(columns=['araci_kurum'], data=bulten)
            timestamp_df = pd.DataFrame(columns=['timestamp'], data=timestamp)
            link_df = pd.DataFrame(columns=['link'], data=link)
            df = pd.concat([tarih_df, hisseler_df, haberler_df, bulten_df, timestamp_df, link_df], axis=1)

            df1 = df

            first_row_count = df.shape[0]
            # BIST Verisi ile Matchleme
            df_bist = pd.read_csv('hissesembolu.csv', delimiter=';')
            df['codes'] = df['codes'].str.upper()
            df['codes'] = df['codes'].str.replace('Ç', 'C')
            df['codes'] = df['codes'].str.replace('Ğ', 'G')
            df['codes'] = df['codes'].str.replace('İ', 'I')
            df['codes'] = df['codes'].str.replace('Ö', 'O')
            df['codes'] = df['codes'].str.replace('Ş', 'S')
            df['codes'] = df['codes'].str.replace('Ü', 'U')
            df = df.rename(columns={'codes': 'BULTEN ADI'})
            df = fuzzy_merge(df, df_bist, 'BULTEN ADI', 'BULTEN ADI', threshold=90)
            df = pd.merge(df, df_bist, on=['BULTEN ADI'])
            df = df[["ISLEM  KODU", "news", "date_list", "araci_kurum", "timestamp", "link"]]
            df = df.rename(columns={'ISLEM  KODU': 'codes'})
            # Baştaki sondaki boşlukları silme
            row_count = df.shape[0]
            if row_count >= 1:
                df['codes'] = df['codes'].str.strip()
                df['news'] = df['news'].str.strip()
            second_row_count = df.shape[0]

            ### NOT TAKEN NEWS
            frames = [df1, df]
            merged = pd.concat(frames)
            not_taken = merged.drop_duplicates(keep=False)
            if len(not_taken) != 0:
                not_taken.to_csv(
                    f"C:/Users/berat/Desktop/Ulakfin - Ortak Data/slack_csv_folded/Marbaş_Yatırım/{str(datetime.datetime.now().date())}_not_taken.csv",
                    encoding="utf-8",
                    index=False, header=False, mode='a')

                client = WebClient(token='xoxb-1310569939731-1373479534900-EAQbiKWSTqT0TxoJI7EfM5TP')

                post_message_to_slack('News which are not parsed.')
                response = client.files_upload(
                    channels="#csv",
                    file=f"C:/Users/berat/Desktop/Ulakfin - Ortak Data/slack_csv_folded/Marbaş_Yatırım/{str(datetime.datetime.now().date())}_not_taken.csv",
                    title=f"not taken csv file {datetime.datetime.now().date()}"
                )
                ###

            # ID Number yazdırma
            old_df = pd.read_csv("C:/Users/berat/Desktop/Ulakfin - Ortak Data/DATA_SON/sirket_haberleri.csv")
            last_id = old_df['news_id'].iloc[-1]
            df['news_id'] = range(last_id + 1, last_id + 1 + len(df))
            df = df[['news_id', 'date_list', 'codes', 'news', 'araci_kurum', 'timestamp', 'link']]

            print(f"{second_row_count} news passed the Stock Name Test from total of {first_row_count} news.")
            post_message_to_slack(
                f"*Accuracy:* {second_row_count} news parsed, out of {first_row_count} news scrapped.")

            print(df)
            df.to_csv("C:/Users/berat/Desktop/Ulakfin - Ortak Data/DATA_SON/sirket_haberleri.csv", encoding="utf-8",
                      index=False, header=False, mode='a')

            print('Marbaş Menkul is completed')
            return df

    except NoSuchElementException:
        print('No data from HSBC Yatırım today.')
        post_message_to_slack('No data from HSBC Yatırım today.')
